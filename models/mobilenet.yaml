---
dataset:
    task:
        background_class: {use: true}
        preprocess:
            shape:
                height: 224
                width: 224
                channels: 3
            validate: {type: central_crop, fraction: 0.875}
            final_cpu:
                - {type: resize, fill: false}
                - {type: linear_map, scale: 2.0, shift: -1.0}
model:
    name: mobilenet_v1
    description:
        MobileNet implementation from::
            https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py
    layers:
        _regu: &regularizer
            type: tensorflow.contrib.layers.l2_regularizer
            scale: 0.00004
        _conv: &conv
            type: convolution
            kernel_size: 3
            stride: 2
            padding: same
            normalizer_fn: tensorflow.contrib.slim.batch_norm
            normalizer_params:
                center: true
                scale: true
                decay: 0.9997
                epsilon: 0.001
            weights_initializer:
                type: tensorflow.truncated_normal_initializer
                stddev: 0.09
            activation_fn: tensorflow.nn.relu6
            weights_regularizer: *regularizer
        _dsconv: &dsconv
            type: module
            kwargs: {stride: null, num_outputs: null}
            layers:
                depthwise:
                    <<: *conv
                    type: depthwise_convolution
                    stride: ^(stride)
                pointwise:
                    <<: *conv
                    kernel_size: [1, 1]
                    stride: 1
                    num_outputs: ^(num_outputs)
                    weights_regularizer: *regularizer
            graph: {from: input, with: [depthwise, pointwise], to: output}
        conv0: {<<: *conv, num_outputs: 32}
        conv1: {<<: *dsconv, stride: 1, num_outputs: 64}
        conv2: {<<: *dsconv, stride: 2, num_outputs: 128}
        conv3: {<<: *dsconv, stride: 1, num_outputs: 128}
        conv4: {<<: *dsconv, stride: 2, num_outputs: 256}
        conv5: {<<: *dsconv, stride: 1, num_outputs: 256}
        conv6: {<<: *dsconv, stride: 2, num_outputs: 512}
        conv7: {<<: *dsconv, stride: 1, num_outputs: 512}
        conv8: {<<: *dsconv, stride: 1, num_outputs: 512}
        conv9: {<<: *dsconv, stride: 1, num_outputs: 512}
        conv10: {<<: *dsconv, stride: 1, num_outputs: 512}
        conv11: {<<: *dsconv, stride: 1, num_outputs: 512}
        conv12: {<<: *dsconv, stride: 2, num_outputs: 1024}
        conv13: {<<: *dsconv, stride: 1, num_outputs: 1024}
        pool: {type: average_pool, kernel_size: 7, stride: 2, padding: valid}
        dropout: {type: dropout, keep_prob: 0.999}
        fc:
            type: convolution
            kernel_size: 1
            num_outputs: $(dataset.task.num_classes)
            activation_fn: null
            normalizer_fn: null
            weights_regularizer: *regularizer
        logits: {type: squeeze, axis: [1, 2]}
    graph:
        from: input
        with: [
            conv0, conv1, conv2, conv3, conv4, conv5, conv6, conv7, conv8,
            conv9, conv10, conv11, conv12, conv13, pool, dropout, fc, logits]
        to: output
